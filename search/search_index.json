{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About this tutorial","text":""},{"location":"#overview","title":"Overview","text":"<p>We will consider the basic informatics problem of sequence alignment from a practical perspective.</p> <p>Our goal is to consider sequence alignment from different angles, and meanwhile develop algorithmic thinking, introduce general concepts for informatics,</p>"},{"location":"#contents","title":"Contents","text":"<p>Techniques: Brute force, Dynamic programming, Divide-and-Conquer, Greedy Combinatorics, Graphs (Shortest paths, Spanning trees), Strings, Hashing</p> <p>Performance: Problem complexity, Absolute performance and scaling, Memory and runtime, Worst-case and average-case asymptotics, Amortized analysis</p> <p>Correctness: Invariants, Approximate vs Exact, Heuristic, Evaluation</p> <p>Central problem: Sequence alignment Pangenomics Data: Sequencing data Applications: Each algorithm will be applied to a basic biological problem Programming: You will be asked to submit your solutions on rosalind.info Heuristic: Genetic algorithms, research tasks on request Central problems: Sequence alignment (global, semi-global, local, suboptimal, MSA), Assembly, Pangenomics Algorithms: Exact, approximate, probabilistic, heuristic algorithms; Greedy, Minimizers Data structures: Genome graph, Suffix tree and suffix array, Bloom filter, HMMs Optimizations: Four Russians method, Bit-parallel Tools: State-of-the-art aligners (minimap2, Edlib, WFA, AStarix, A*PA, GraphAligner) Homeworks: rosalind.info problems, edit a Wikipedia page in computational biology</p>"},{"location":"#goal","title":"Goal","text":"<p>Olympiad informatics, </p>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p>You will need to feel confortable with middle-school mathematics and have basic programming skillsw with a language like C++ or Python.</p>"},{"location":"SUMMARY/","title":"Sequence alignment tutorial","text":"<ul> <li>Intro<ul> <li>Pairwise alignment<ul> <li>Global alignment, graphs, shortest paths</li> <li>Data: technical and biological variation</li> <li>Optimization: edit distance</li> <li>Applications, goal</li> </ul> </li> <li>Naive solutions<ul> <li>Brute force (correct but exponentially slow)</li> <li>Greedy (fast but wrong)</li> <li>Heuristic algorithms (fast but often wrong)</li> </ul> </li> <li>Dynamic programming (1953) (correct and quadratic)<ul> <li>Global alignment: Needleman-Wunsch algorithm (1970)</li> <li>Best path reconstruction</li> <li>Number of optimal paths</li> <li>Recursive and iterative implementations</li> <li>Decouple problem and solution</li> <li>Correctness, definitions, invariants</li> <li>Worst case runtime and memory</li> <li>DP framework: topological ordering of subproblems</li> </ul> </li> <li>Other alignments<ul> <li>Local alignment: Smith-Waterman\u2019s algorithm (1981)</li> <li>Semi-global alignment / pattern matching / read mapping</li> <li>Mapping vs alignment</li> <li>Extension, global-extension, overlap</li> <li>Longest common subsequence (LCS)</li> <li>Regular expression (RegExp)</li> <li>Probabilistic (with Phred values, HMMs)</li> <li>Metrics (Affine)</li> </ul> </li> <li>Limitations</li> <li>Terms</li> </ul> </li> <li>Global<ul> <li>How to make an algorithm fast and scalable?<ul> <li>Greedy</li> <li>Divide and conquer (binary search, trees, exponential search)</li> <li>Precomputation (indexing, hashing, DP)</li> <li>Hardware (bit-parallel, GPU)</li> </ul> </li> <li>Sliding (simple greedy matching)</li> <li>Linear memory<ul> <li>Wrong approaches</li> <li>Binary search (200 BCE)</li> <li>Divide-and-Conquer</li> <li>Hirschberg\u2019s algorithm (1975)</li> </ul> </li> <li>Shortest path algorithms<ul> <li>Output sensitive performance</li> <li>Dijkstra\u2019s algorithm (1956) for alignment (1986)</li> </ul> </li> <li>Exponential search<ul> <li>Binary search by the answer</li> <li>Fast exponentiation</li> <li>Band doubling (1985), Edlib (tool)</li> <li>Amortized analysis (Vector doubling, two-pointer, tree traversal)</li> </ul> </li> <li>Diagonal transition (1985)<ul> <li>furthest-reaching points, wavefronts, WFA (tool)</li> </ul> </li> <li>Informed search<ul> <li>Precomputation before alignment</li> <li>Contours, thresholds (1977)</li> </ul> </li> <li>Bithacks<ul> <li>Bit-parallel (1999)</li> <li>Four Russians technique for \\(O(n^2/n)\\) (1980)</li> <li>GPU parallelization</li> </ul> </li> </ul> </li> <li>Semi-global<ul> <li>Indexing</li> <li>BWT</li> <li>Hashing<ul> <li>Rolling hash (Rabin-Karp algorithm)</li> <li>Hash table: hash + precomputation)</li> <li>Inexact hashing (sketches, minimizers)</li> </ul> </li> <li>Suffix trees (1973)<ul> <li>Data structures</li> <li>KMP algorithm for single query</li> <li>Reference indexing</li> <li>Queries preparation (Aho-Corasick)</li> </ul> </li> <li>Inexact, heuristic, probabilistic<ul> <li>minimap2 (tool)</li> <li>GraphAligner (tool)</li> <li>Genetic algorithms</li> </ul> </li> <li>Pangenomics<ul> <li>Graph reference / Variant graph</li> <li>Metagenomics</li> <li>vg (tool)</li> </ul> </li> <li>Pseudoalignments</li> </ul> </li> <li>Heuristic<ul> <li>What is heuristic</li> <li>A* algorithm (1968)</li> <li>Scaling with sequence length<ul> <li>Seed heuristic</li> <li>Match pruning</li> </ul> </li> <li>Scaling with error rate<ul> <li>Chaining seed heuristic</li> <li>Inexact seed matches</li> <li>Pruning</li> <li>Chaining</li> <li>Gap cost</li> <li>Affine</li> <li>Variable-len seeds</li> </ul> </li> <li>Scaling with reference size<ul> <li>Trie</li> <li>Seed heuristic on trie</li> <li>Seed heuristic without trie</li> </ul> </li> <li>Applications<ul> <li>A* for global alignment<ul> <li>A*PA (tool)</li> </ul> </li> <li>A* for semi-global alignment<ul> <li>AStarix (tool)</li> </ul> </li> </ul> </li> <li>Open problems<ul> <li>Incomplete relaxations</li> <li>Inexact relaxations</li> <li>Proof of linear scaling for global alignment</li> <li>Proof of logarithic reference scaling for semi-global alignment</li> <li>Performance of \\A*</li> <li>Apply to local alignment</li> <li>Apply to MSA</li> </ul> </li> </ul> </li> <li>MSA<ul> <li>Multiple sequence alignment</li> <li>Tools</li> </ul> </li> <li>Theory<ul> <li>Limitations</li> </ul> </li> </ul>"},{"location":"history/","title":"History","text":"<p>Overview of exact global alignment methods TODO: integrate here TODO: non-global alignment methods</p>"},{"location":"overview/","title":"Overview","text":"<p>Sequence alignment is awesome.</p>"},{"location":"terms/","title":"Terms","text":"<p>Note on terminology (TODO: move all here)</p>"},{"location":"transcriptomics/","title":"Transcriptomics (RNA) alignment","text":"<p>Batch or single-cell.</p>"},{"location":"transcriptomics/#problems","title":"Problems","text":""},{"location":"transcriptomics/#techniques","title":"Techniques","text":"<ul> <li>decoy sequences</li> </ul>"},{"location":"transcriptomics/#tools","title":"Tools","text":"<ul> <li>Salmon</li> <li>Kallisto</li> </ul>"},{"location":"tutorial/","title":"This tutorial","text":"<p>Inteactive coding DataCamp special version for Python and R in Markdown</p> <code>         b = 6     </code> <code> </code> <code>         a &lt;- 5         print(a)     </code> <code>         test_object(\"a\")         test_function(\"print\")         success_msg(\"Great job!\")     </code> Use the assignment operator (<code>&lt;-</code>) to create the variable <code>a</code>."},{"location":"types/","title":"Types","text":"<p>Alignment types</p>"},{"location":"astar/astar-semiglobal/","title":"A* for semi-global","text":""},{"location":"astar/astar-semiglobal/#a-intro","title":"A* intro","text":"<p>A* rullz.</p>"},{"location":"astar/astar-semiglobal/#admissible-heuristic","title":"Admissible heuristic","text":"<p>A function that is optimistic.</p>"},{"location":"astar/astar-semiglobal/#seed-heuristic","title":"Seed heuristic","text":""},{"location":"intro/pa-dp-nw/","title":"Global alignment: Needleman-Wunsch algorithm (1970)","text":"\\[ \\int x dx = \\frac{x^2}{2} + C \\] <pre><code>const THREE_HOURS_IN_SECONDS: u32 = 60 * 60 * 3;\n</code></pre> <pre><code>for i in range(5):\n    print(i)\n</code></pre>"},{"location":"intro/pa-dp/","title":"Dynamic programming (DP)","text":"<p>DP is a powerful technique for combinatorial problems, such as optimization and counting. A problem is recursively split into overlapping subproblems, such that the solutions of the subproblems can be merged into to a solution of the bigger problem. Introduced by Bellman (1954)</p> <p>DP <sup>1</sup></p> <p>TODO: picture of exponentially many overlapping alignment subproblems</p> <p>Distinguish from Divide&amp;Conquere:</p> <ul> <li>DP is about skipping recomputation for the same subtask. This could lead to an exponential acceleration.</li> <li>The subtasks for D&amp;C are independent: they don\u2019t overlap so cannot be reused.</li> </ul> <p>Distinguish from Greedy (assuming an optimization task):</p> <ul> <li>DP considers all possible steps that lead to a subtask solution \u2013 at least one of them must bring an optimal solution</li> <li>Note that some greedies can also be provably optimal/correct.</li> </ul> <ol> <li> <p>Richard Bellman. The theory of dynamic programming. Bulletin of the American Mathematical Society, 60(6):503\u2013515, 1954.\u00a0\u21a9</p> </li> </ol>"},{"location":"intro/pa-naive/","title":"Bad solutions","text":"<p>TODO: greedy, with pictures</p> <p>TODO: brute force, with pictures</p> <p>TODO: heuristic: choose similar patches and connect them somehow</p>"},{"location":"intro/pa-problem/","title":"Pairwise alignment problem","text":"<p>Comparing two text sequences is one of the most basic tasks with data. If the sequences have no mistakes, then sequence \\(A\\) can be aligned to sequence \\(B\\) letter-to-letter without mistakes between the aligned letters. Such an alignment can be made by iterating through the corresponding word letters just once and checking if they match.</p> <p>TODO: image of an exact global alignment</p> <p>In many real-world applications, though, errors happen and our alignment algorithm has to tolerate them. If letters can be substituded, our alignment may include mismatching letters that are aligned to each other. The number of such mistamches is called Hamming distance between \\(A\\) and \\(B\\)\u2014counting them only takes one pass through the sequences. It is often useful for bit-sequences.</p> <p>TODO: image of an global alignment with hamming distance = 2</p> <p>What if letters may be not only substituted, but also inserted or deleted? Now aligning is not streigh-forward anymore since there are many possible alignments, each including different number of mismatching corresponding letters.</p> <p>TODO: 2 images of global alignments with different Levenshtein distances</p> <p>Among all alignments, we can try finding one that minimizes the number of necessary edits (subsitutions, insertions and deletions). The minimal number of such edits needed to convert \\(A\\) to \\(B\\) is called Levenshtein distance. Note that converting \\(B\\) to \\(A\\) takes the same number of edits.</p> <p>We can generalize the Levenshtein distance to different costs of the edit operations, e.g. subtitutions may each cost \\(1\\) but gaps (i.e. insertions and deletions) may cost \\(5\\).</p> <p>TODO: An alignment with edit distance</p>"}]}